{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìé Embedding Decathlon HTML Docs into Pinecone using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"openai_api_key\")\n",
    "PINECONE_API_KEY = os.getenv(\"pinecone_api_key\")\n",
    "PINECONE_ENV_KEY = os.getenv(\"pinecone_env_key\")\n",
    "PINECONE_INDEX = os.getenv(\"pinecone_index\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Decathlon Documents from the Decathlon website (Home, FAQ, Warranty, Product Returns etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader([\"https://www.decathlon.ma/\", \"https://www.decathlon-united.com/fr\", \"https://www.decathlon.ma/content/63-garantie\", \"https://www.decathlon.ma/content/87-retour-echange\", \n",
    "                        \"https://www.decathlon.ma/content/88-cartecadeaux\", \"https://www.decathlon.ma/content/96-cliquez-et-retirez\", \"https://www.decathlon.ma/content/85-echo-conception\",\n",
    "                        \"https://www.decathlon.ma/content/86-nos-innovations\", \"https://www.decathlon.ma/module/decab2b/b2b?icn=HomePage-Footer-DecathlonPRO\", \"https://www.decathlon.ma/page/acheter-en-ligne.html\", \n",
    "                        \"https://www.decathlon.ma/page/consulter-stock.html\", \"https://www.decathlon.ma/content/1-livraison\", \"https://www.decathlon.ma/page/rappelproduit.html\", \"https://www.decathlon.ma/page/cgu_cgv.html\"\n",
    "                        \"https://www.decathlon.ma/page/donnees-personnelles-et-cookies.html\", \"https://www.decathlon.ma/page/conditions-de-publication-des-avis.html\", \"https://www.decathlon.ma/page/mention_legale.html\",\n",
    "                        \"https://www.decathlon.ma/content/102-decathlon-occasion?icn=ServicesPage-occasion\", \"https://www.decathlon.ma/5080-promotions?icn=HomePage-Menu-Promotions\", \"https://www.decathlon.ma/nous-contacter\"])\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1547"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get 1547 Documents after loading the HTML Files using Langchain WebBaseLoader and then splittingn them"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to embedd the documents and then store them into a Pincecone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_ENV_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name=PINECONE_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pinecone.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the docs into the Pinecone index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_store = Pinecone.from_texts([d.page_content for d in docs], embedding, index_name=index_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚õìÔ∏è Langchain LLM Chatbot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use gpt-3.5 OpenAI model to create a chatbot that can answer customers questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_from_query(db, query, k=4):\n",
    "        \"\"\"\n",
    "        Function that generates a response to a customer question using the gpt-3.5-model and the docs provided\n",
    "        \"\"\"\n",
    "\n",
    "        docs = db.similarity_search(query, k=k)\n",
    "        docs_page_content = \" \".join([d.page_content for d in docs])\n",
    "\n",
    "        chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "        # Template to use for the system message prompt\n",
    "        template = \"\"\"\n",
    "            Tu es un assistant utile qui peut r√©pondre aux questions des clients sur une plateforme de commerce √©lectronique qui vend des equipements de sport\n",
    "            nomm√© \"Decathlon\" bas√© sur les donn√©es html trouv√©es sur leur site Web¬†: {docs}\n",
    "            \n",
    "            D'abord tu classe le sentiment de la question ou de la phrase du client, et tu utilisez uniquement les informations factuelles du code HTML pour r√©pondre √† la question, \n",
    "            et tu r√©ponds en prenant compte du sentiment du client.\n",
    "            \n",
    "            Si tu sents que tu n'as pas assez d'informations pour r√©pondre √† la question, r√©ponds par \"D√©sol√©, je ne sais pas la r√©ponse √† ta question.\".\n",
    "            \n",
    "            Tes r√©ponses doivent √™tre d√©taill√©es.\n",
    "            \"\"\"\n",
    "\n",
    "        system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "        # Human question prompt\n",
    "        human_template = \"R√©ponds √† la question suivante: {question}\"\n",
    "        human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "        chat_prompt = ChatPromptTemplate.from_messages(\n",
    "            [system_message_prompt, human_message_prompt]\n",
    "        )\n",
    "\n",
    "        chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "\n",
    "        try:\n",
    "            response = chain.run(question=query, docs=docs_page_content)\n",
    "            response = response.replace(\"\\n\", \"\")\n",
    "            return response\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Pour effectuer un retour produit en magasin chez Decathlon, vous devez vous rendre dans l'un des magasins Decathlon au Maroc avec le produit que vous souhaitez retourner. Une fois sur place, vous pouvez soit √©changer votre article, soit vous faire rembourser. Cette politique de retour est valable pour tous les produits achet√©s sur le site web de Decathlon au Maroc et dans l'ensemble de leurs magasins dans le pays. Cependant, pour les achats effectu√©s √† l'√©tranger, le retour est limit√© aux produits de marques passion Decathlon.\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_response_from_query(doc_store, \"COMMENT EFFECTUER MON RETOUR PRODUIT EN MAGASIN ?\")\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the already created Index to query the db and generate a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Pinecone.from_existing_index(index_name, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Pour effectuer un retour produit en magasin chez Decathlon Maroc, voici les √©tapes √† suivre :1. Rendez-vous dans n'importe quel magasin Decathlon Maroc avec votre produit et votre preuve d'achat.2. Pr√©sentez votre produit et votre preuve d'achat √† un membre du personnel du magasin.3. Vous pouvez choisir entre un √©change ou un remboursement.4. Si vous √©changez votre produit, vous pouvez choisir un produit similaire de m√™me valeur ou payer la diff√©rence si le nouveau produit est plus cher.5. Si vous demandez un remboursement, vous serez rembours√©(e) sur votre moyen de paiement initial.Notez que cette politique de retour est valable pour tous les produits achet√©s sur www.decathlon.ma et dans l'ensemble des magasins Decathlon Marocains. Pour les achats effectu√©s √† l‚Äô√©tranger, le retour est limit√© aux produits de marques passion DECATHLON.\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_response_from_query(docsearch, \"COMMENT EFFECTUER UN RETOUR DE PRODUIT EN MAGASIN ?\")\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
